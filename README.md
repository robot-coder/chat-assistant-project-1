# Chat Assistant Project

## Overview
This project implements a Chat Assistant using FastAPI for the backend and a JavaScript frontend. The assistant allows users to interact with different LLMs and maintains a continuous conversation.

## Requirements
1. Frontend developed using Aider or Roo Code.
2. Backend developed using FastAPI.
3. Integration with LiteLLM for LLM calls.
4. User selection for LLM.
5. Continuous conversation handling.
6. UI similar to ChatGPT.
7. Deployment on Render.com.
8. OpenRouter.ai API Key.
9. Thematic focus for the Chat Assistant.

## Extensions
- Text file uploads for prompt context.
- Image file uploads for multimodal LLMs.
- Side-by-side LLM response comparison.

## Deployment
Link to the deployed Chat Assistant: [Your Render.com Link Here]

## Usage
To run the Chat Assistant locally:
1. Clone the repository.
2. Install the required packages.
3. Run the FastAPI server.
4. Open the `index.html` in a web browser.

## License
This project is licensed under the MIT License.